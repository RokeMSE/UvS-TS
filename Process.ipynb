{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad75dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6ff975",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_folder = f\"D:\\\\Research\\\\Test_data\"\n",
    "all_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b853f1f",
   "metadata": {},
   "source": [
    "# Hàm tạo ma trận kề"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81715725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/liyaguang/DCRNN/blob/master/scripts/gen_adj_mx.py\n",
    "\n",
    "def get_adjacency_matrix(distance_df, sensor_ids, normalized_k=0.1):\n",
    "    \"\"\"\n",
    "\n",
    "    :param distance_df: data frame with three columns: [from, to, distance].\n",
    "    :param sensor_ids: list of sensor ids.\n",
    "    :param normalized_k: entries that become lower than normalized_k after normalization are set to zero for sparsity.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    num_sensors = len(sensor_ids)\n",
    "    dist_mx = np.zeros((num_sensors, num_sensors), dtype=np.float32)\n",
    "    dist_mx[:] = np.inf\n",
    "    # Builds sensor id to index map.\n",
    "    sensor_id_to_ind = {}\n",
    "    for i, sensor_id in enumerate(sensor_ids):\n",
    "        sensor_id_to_ind[sensor_id] = i\n",
    "\n",
    "    # Fills cells in the matrix with distances.\n",
    "    for row in distance_df.values:\n",
    "        if row[0] not in sensor_id_to_ind or row[1] not in sensor_id_to_ind:\n",
    "            continue\n",
    "        dist_mx[sensor_id_to_ind[row[0]], sensor_id_to_ind[row[1]]] = row[2]\n",
    "\n",
    "    # Calculates the standard deviation as theta.\n",
    "    distances = dist_mx[~np.isinf(dist_mx)].flatten()\n",
    "    std = distances.std()\n",
    "    adj_mx = np.exp(-np.square(dist_mx / std))\n",
    "    # Make the adjacent matrix symmetric by taking the max.\n",
    "    # adj_mx = np.maximum.reduce([adj_mx, adj_mx.T])\n",
    "\n",
    "    adj_mx_test = np.exp(-np.square(dist_mx / std))\n",
    "    print(np.sum(adj_mx_test >= normalized_k) / adj_mx_test.size)\n",
    "\n",
    "    # Sets entries that lower than a threshold, i.e., k, to zero for sparsity.\n",
    "    adj_mx[adj_mx < normalized_k] = 0\n",
    "    return sensor_ids, sensor_id_to_ind, adj_mx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ce3c3",
   "metadata": {},
   "source": [
    "# 1. Hàm đọc dữ liệu từ các file zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be69a66b",
   "metadata": {},
   "source": [
    "## 1.1 Đọc và xử lí dữ liệu từ file zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac2f75da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for filename in os.listdir(download_folder):\n",
    "#     if filename.endswith(\".txt.gz\"):\n",
    "#         gz_path = os.path.join(download_folder, filename)\n",
    "        \n",
    "#         with gzip.open(gz_path, 'rb') as f_in:\n",
    "#             with open('temp.txt', 'wb') as f_out:\n",
    "#                 shutil.copyfileobj(f_in, f_out)\n",
    "        \n",
    "#         data = pd.read_table(\"temp.txt\", sep=\",\", header=None)\n",
    "#         data = data.iloc[:, :12]\n",
    "#         data.columns = [\"timestamp\", \"station\", \"district\", \"freeway\", \"direction\", \"lanetype\",\n",
    "#         \"station_length\", \"samples\", \"observed_percentage\", \"total_flow\", \"avg_occ\", \"avg_speed\"]\n",
    "#         data = data[data['lanetype'] == 'ML']\n",
    "#         data = data[[\"timestamp\", \"station\", \"observed_percentage\", \"total_flow\", \"avg_occ\", \"avg_speed\"]]\n",
    "#         data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"])\n",
    "#         all_data.append(data)\n",
    "#         print(filename)\n",
    "\n",
    "# with open(\"all_data.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(all_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ff24ce",
   "metadata": {},
   "source": [
    "## 1.2 Đọc dữ liệu từ file pkl(dữ liệu trong các file zip đã được đọc và lưu lại)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb53880",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_data.pkl\", \"rb\") as f:\n",
    "    all_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a3c88",
   "metadata": {},
   "source": [
    "# 2. Xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44beb7",
   "metadata": {},
   "source": [
    "## 2.1 Lấy các mẫu được quan sát hơn 1 tỉ lệ cho trước và xuất hiện liên tục 1 khoảng thời gian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0186954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số sensor giữ lại: 1062\n"
     ]
    }
   ],
   "source": [
    "# Lọc lấy các mẫu có tỉ lệ ghi nhận cao(đáng tin cậy), loại bỏ các mẫu nội suy nhiều\n",
    "data = [df[df['observed_percentage'] >= 99] for df in all_data]\n",
    "\n",
    "# Lọc lấy danh sách các sensor xuất hiện nhiều(liên tục 1 khoảng thời gian)\n",
    "min_consecutive_days = 60\n",
    "sensor_streaks = defaultdict(int)\n",
    "max_streaks = defaultdict(int)\n",
    "\n",
    "for df in data:\n",
    "    sensors_today = set(df['station'].unique())\n",
    "    \n",
    "    for sensor in sensors_today:\n",
    "        sensor_streaks[sensor] += 1\n",
    "        max_streaks[sensor] = max(max_streaks[sensor], sensor_streaks[sensor])\n",
    "    \n",
    "    missing_sensors = set(sensor_streaks.keys()) - sensors_today\n",
    "    for sensor in missing_sensors:\n",
    "        sensor_streaks[sensor] = 0\n",
    "\n",
    "valid_sensors = {s for s, streak in max_streaks.items() if streak >= min_consecutive_days}\n",
    "print(f\"Số sensor giữ lại: {len(valid_sensors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe65bdd",
   "metadata": {},
   "source": [
    "## 2.2 Đọc metadata các sensor, xóa các sensor trùng vị trí địa lí và các sensor đã loại ở bước trên. Chỉ lấy phần dữ liệu còn lại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc metadata lấy danh sách các sensor, lấy các sensor của đường \"ML\", lấy các sensor trong danh sách valid_sensor, loại bỏ các sensor trùng địa điểm(cùng kinh độ và vĩ độ)\n",
    "meta = pd.read_csv(\"../Meta_District4.txt\", sep='\\t')\n",
    "meta = meta[meta['Type'] == 'ML']\n",
    "meta = meta[meta['ID'].isin(valid_sensors)]\n",
    "meta = (\n",
    "    meta\n",
    "    .sort_values('ID')  # Đảm bảo station nhỏ nhất lên trước\n",
    "    .drop_duplicates(subset=['Latitude', 'Longitude'], keep='first')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "# Lấy danh sách valid_sensor mới\n",
    "sensors_df = meta[['ID', 'Latitude', 'Longitude']]\n",
    "# Lấy các dữ liệu từ các sensor hợp lệ\n",
    "raw_data = [df[df['station'].isin(valid_sensors)] for df in data]\n",
    "raw_data = pd.concat(raw_data, ignore_index=True)\n",
    "raw_data = raw_data.sort_values(['timestamp', 'station'])\n",
    "raw_data['timestamp'] = pd.to_datetime(raw_data['timestamp'])\n",
    "\n",
    "# raw_data.to_csv('Raw_Data.csv', index = False)\n",
    "# np.save(\"sensors_df.npy\", np.array(sensors_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f32c1a",
   "metadata": {},
   "source": [
    "## 2.3 Đọc dữ liệu đã xử lí"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd0559db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data = pd.read_csv('Raw_Data.csv')\n",
    "# raw_data['timestamp'] = pd.to_datetime(raw_data['timestamp'])\n",
    "# sensors_df = np.load(\"sensors_df.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e301d",
   "metadata": {},
   "source": [
    "# 3. Chuyển thành numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac738326",
   "metadata": {},
   "source": [
    "## 3.1 Xử lí DF, tạo mốc thời gian, tạo mảng numpy array. Gán các phần tử trong DF vào array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo các mốc thời gian\n",
    "start_time = raw_data[\"timestamp\"].min()\n",
    "end_time = raw_data[\"timestamp\"].max()\n",
    "full_time_index = pd.date_range(start=start_time, end=end_time, freq=\"5min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99c57730",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_to_ind = {t: i for i, t in enumerate(full_time_index)}\n",
    "sensor_id_to_ind = {s: i for i, s in enumerate(sensors_df[\"ID\"].values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c048320",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.full((len(time_to_ind), len(sensor_id_to_ind), 3), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8252f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in raw_data.itertuples(index=False):\n",
    "    x = time_to_ind.get(row.timestamp) \n",
    "    y = sensor_id_to_ind.get(row.station)\n",
    "    result[x, y, 0] = row.total_flow\n",
    "    result[x, y, 1] = row.avg_speed\n",
    "    result[x, y, 2] = row.avg_occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52d5967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4062192\n",
      "(34848, 1053, 3)\n",
      "110084832\n",
      "3.6900560469584036\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(result).sum())\n",
    "print(result.shape)\n",
    "total_elements = result.size\n",
    "total_nan = np.isnan(result).sum()\n",
    "nan_ratio = total_nan / total_elements * 100\n",
    "print(total_elements)\n",
    "print(nan_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24c172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/PEMSBAY.npy\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0920961e",
   "metadata": {},
   "source": [
    "## 3.2 Đọc dữ liệu numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_array = np.load(\"/PEMSBAY.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b2918e",
   "metadata": {},
   "source": [
    "# 4. Tạo adj_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d98659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = []\n",
    "for i in range(len(sensors_df) - 1):\n",
    "    for j in range(i + 1, len(sensors_df)):\n",
    "        dis = ((sensors_df[\"Latitude\"][i] - sensors_df['Latitude'][j]) ** 2 + (sensors_df['Longitude'][i] - sensors_df['Longitude'][j]) ** 2) ** 0.5\n",
    "        distance.append([sensors_df['ID'][i], sensors_df['ID'][j], dis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61492d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_df = pd.DataFrame(distance, columns=['from', 'to', 'distance'])\n",
    "sensors_ids = sensors_df['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e27f26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27477230072988224\n"
     ]
    }
   ],
   "source": [
    "sensor_ids, sensor_id_to_ind, adj_mx = get_adjacency_matrix(distance_df, sensors_ids, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c45079",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = (sensor_ids, sensor_id_to_ind, adj_mx)\n",
    "with open(\"/adj_mx_bay.pkl\", \"wb\") as f:\n",
    "    pickle.dump(to_save, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
